# WebWhisper ğŸ™ï¸

A modern web application for real-time speech recognition and AI-powered conversation, built with Next.js and TypeScript.

## ğŸš€ Features

- **Real-time Speech Recognition**: Convert speech to text using Web Speech API
- **AI-Powered Conversations**: Integrated with Google Gemini for intelligent responses
- **Modern UI**: Clean and responsive interface built with React
- **TypeScript Support**: Full type safety throughout the application
- **Fast Performance**: Optimized with Next.js for superior user experience

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 14
- **Language**: TypeScript (73.3%), JavaScript (25.7%)
- **Styling**: CSS (1%)
- **AI Integration**: Google Gemini API
- **Speech Recognition**: Web Speech API
- **Package Manager**: npm/yarn

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:
- Node.js (version 16 or higher)
- npm or yarn
- A Google Gemini API key

## ğŸ”§ Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/greywarden07/WebWhisper.git
   cd WebWhisper
   ```

2. **Install dependencies**
   ```bash
   npm install
   # or
   yarn install
   ```

3. **Set up environment variables**
   Create a `.env.local` file in the root directory:
   ```env
   GEMINI_API_KEY=your_gemini_api_key_here
   NEXT_PUBLIC_API_URL=http://localhost:3000/api
   ```

4. **Run the development server**
   ```bash
   npm run dev
   # or
   yarn dev
   ```

5. **Open your browser**
   Navigate to [http://localhost:3000](http://localhost:3000) to see the application.

## ğŸš¦ Usage

1. **Start a Conversation**: Click the microphone button to begin speech recognition
2. **Speak Naturally**: The app will convert your speech to text in real-time
3. **AI Response**: Get intelligent responses powered by Google Gemini
4. **Continue Chatting**: Build upon the conversation with follow-up questions

## ğŸ“‚ Project Structure

```
WebWhisper/
â”œâ”€â”€ public/          # Static assets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/  # React components
â”‚   â”œâ”€â”€ pages/       # Next.js pages
â”‚   â”œâ”€â”€ styles/      # CSS styles
â”‚   â”œâ”€â”€ types/       # TypeScript type definitions
â”‚   â””â”€â”€ utils/       # Utility functions
â”œâ”€â”€ package.json     # Dependencies and scripts
â””â”€â”€ README.md        # Project documentation
```

## ğŸ”‘ Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GEMINI_API_KEY` | Your Google Gemini API key | Yes |
| `NEXT_PUBLIC_API_URL` | API base URL | Yes |

## ğŸš€ Deployment

### Vercel (Recommended)

1. Push your code to GitHub
2. Connect your repository to [Vercel](https://vercel.com)
3. Add environment variables in Vercel dashboard
4. Deploy automatically on every push

### Other Platforms

The application can be deployed on any platform that supports Next.js:
- Netlify
- Railway
- Heroku
- AWS
- Google Cloud Platform

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**greywarden07**
- GitHub: [@greywarden07](https://github.com/greywarden07)

## ğŸ™ Acknowledgments

- Google for providing the Gemini AI capabilities
- The Next.js team for the amazing framework
- Web Speech API for speech recognition functionality

## ğŸ“ Support

If you have any questions or need help, please open an issue in the GitHub repository.

---

**Built with â¤ï¸ using Next.js and TypeScript**
